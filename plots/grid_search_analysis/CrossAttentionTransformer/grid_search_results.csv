model_name,hidden_dim,num_layers,num_heads,trainable_params,best_val_loss,best_val_acc,best_epoch,total_epochs
CrossAttentionTransformer_d32_l4_h8,32,4,8,55464,0.00021856233070138842,0.7402436137199402,21,32
CrossAttentionTransformer_d32_l6_h8,32,6,8,81224,0.0002137473929906264,0.7544199824333191,26,37
CrossAttentionTransformer_d32_l8_h8,32,8,8,106984,0.00028563867090269923,0.6357526183128357,7,18
CrossAttentionTransformer_d32_l10_h8,32,10,8,132744,0.00021553474653046578,0.7544138431549072,15,26
CrossAttentionTransformer_d64_l6_h8,64,6,8,315299,0.0002032085321843624,0.7718178629875183,35,46
CrossAttentionTransformer_d64_l4_h8,64,4,8,214627,0.00020451139425858855,0.7579948306083679,28,39
CrossAttentionTransformer_d64_l8_h8,64,8,8,415971,0.00020472814503591508,0.7675369381904602,19,30
CrossAttentionTransformer_d64_l10_h8,64,10,8,516643,0.0002058388345176354,0.7709345817565918,20,31
CrossAttentionTransformer_d128_l4_h8,128,4,8,843166,0.00020069375750608742,0.7625354528427124,11,22
CrossAttentionTransformer_d128_l8_h8,128,8,8,1639070,0.00019840084132738411,0.7707094550132751,16,27
CrossAttentionTransformer_d128_l6_h8,128,6,8,1241118,0.00019734061788767576,0.7743589878082275,21,32
CrossAttentionTransformer_d128_l10_h8,128,10,8,2037022,0.00019699480617418885,0.780867874622345,32,43
CrossAttentionTransformer_d256_l4_h8,256,4,8,3338873,0.0002049833710771054,0.7708525657653809,9,20
CrossAttentionTransformer_d256_l8_h8,256,8,8,6503545,0.00020732340635731816,0.7716635465621948,11,22
CrossAttentionTransformer_d256_l6_h8,256,6,8,4921209,0.0002016954676946625,0.7813436985015869,19,30
CrossAttentionTransformer_d256_l10_h8,256,10,8,8085881,0.00020780933846253902,0.7739771008491516,15,26
